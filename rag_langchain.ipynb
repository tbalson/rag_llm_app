{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import dotenv\n",
    "from pathlib import Path\n",
    "\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from langchain_community.document_loaders.text import TextLoader\n",
    "from langchain_community.document_loaders import (\n",
    "    WebBaseLoader, \n",
    "    PyPDFLoader, \n",
    "    Docx2txtLoader,\n",
    ")\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.chains import create_history_aware_retriever, create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_doc_to_db():\n",
    "    # Use loader according to doc type\n",
    "    if \"rag_docs\" in st.session_state and st.session_state.rag_docs:\n",
    "        docs = [] \n",
    "        for doc_file in st.session_state.rag_docs:\n",
    "            if doc_file.name not in st.session_state.rag_sources:\n",
    "                if len(st.session_state.rag_sources) < DB_DOCS_LIMIT:\n",
    "                    os.makedirs(\"source_files\", exist_ok=True)\n",
    "                    file_path = f\"./source_files/{doc_file.name}\"\n",
    "                    with open(file_path, \"wb\") as file:\n",
    "                        file.write(doc_file.read())\n",
    "\n",
    "                    try:\n",
    "                        if doc_file.type == \"application/pdf\":\n",
    "                            loader = PyPDFLoader(file_path)\n",
    "                        elif doc_file.name.endswith(\".docx\"):\n",
    "                            loader = Docx2txtLoader(file_path)\n",
    "                        elif doc_file.type in [\"text/plain\", \"text/markdown\"]:\n",
    "                            loader = TextLoader(file_path)\n",
    "                        #elif doc_file.name.endswith(\".xlsx\"):\n",
    "                            #loader = UnstructuredExcelLoader(file_path, mode='elements')\n",
    "                        elif doc_file.name.endswith(\".xlsx\"):\n",
    "                            loader = AzureAIDocumentIntelligenceLoader(\n",
    "                                 api_endpoint=os.getenv(\"AZ_OPENAI_ENDPOINT\"),\n",
    "                                 api_key=os.getenv(\"AZ_OPENAI_API_KEY\"),\n",
    "                                 file_path=file_path,\n",
    "                                 api_model=\"prebuilt-layout\"\n",
    "                            )\n",
    "                        elif doc_file.name.endswith(\".py\"):\n",
    "                            loader = PythonLoader(file_path)\n",
    "                        elif doc_file.name.endswith(\".csv\"):\n",
    "                            loader = CSVLoader(file_path)\n",
    "                        else:\n",
    "                            st.warning(f\"Document type {doc_file.type} not supported.\")\n",
    "                            continue\n",
    "# Lets use a smarter lib https://python.langchain.com/v0.2/docs/integrations/document_loaders/microsoft_excel/ TBB 4/30/25\n",
    "                        docs.extend(loader.load())\n",
    "                        st.session_state.rag_sources.append(doc_file.name)\n",
    "\n",
    "                    except Exception as e:\n",
    "                        st.toast(f\"Error loading document {doc_file.name}: {e}\", icon=\"⚠️\")\n",
    "                        print(f\"Error loading document {doc_file.name}: {e}\")\n",
    "                    \n",
    "                    finally:\n",
    "                        os.remove(file_path)\n",
    "\n",
    "                else:\n",
    "                    st.error(F\"Maximum number of documents reached ({DB_DOCS_LIMIT}).\")\n",
    "\n",
    "        if docs:\n",
    "            _split_and_load_docs(docs)\n",
    "            st.toast(f\"Document *{str([doc_file.name for doc_file in st.session_state.rag_docs])[1:-1]}* loaded successfully.\", icon=\"✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load docs\n",
    "\n",
    "doc_paths = [\n",
    "    \"docs/test_rag.pdf\",\n",
    "    \"docs/test_rag.docx\",\n",
    "]\n",
    "\n",
    "docs = [] \n",
    "for doc_file in doc_paths:\n",
    "    file_path = Path(doc_file)\n",
    "\n",
    "    try:\n",
    "        if doc_file.endswith(\".pdf\"):\n",
    "            loader = PyPDFLoader(file_path)\n",
    "        elif doc_file.endswith(\".docx\"):\n",
    "            loader = Docx2txtLoader(file_path)\n",
    "        elif doc_file.endswith(\".txt\") or doc_file.name.endswith(\".md\"):\n",
    "            loader = TextLoader(file_path)\n",
    "        elif doc_file.name.endswith(\".xlsx\"):\n",
    "            loader = AzureAIDocumentIntelligenceLoader(\n",
    "                api_endpoint=os.getenv(\"AZ_OPENAI_ENDPOINT\"),\n",
    "                api_key=os.getenv(\"AZ_OPENAI_API_KEY\"),\n",
    "                file_path=file_path,\n",
    "                api_model=\"prebuilt-layout\"\n",
    "                            )  \n",
    "        else:\n",
    "            print(f\"Document type {doc_file.type} not supported.\")\n",
    "            continue\n",
    "\n",
    "        docs.extend(loader.load())\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading document {doc_file.name}: {e}\")\n",
    "\n",
    "\n",
    "# Load URLs\n",
    "\n",
    "url = \"https://docs.streamlit.io/develop/quick-reference/release-notes\"\n",
    "try:\n",
    "    loader = WebBaseLoader(url)\n",
    "    docs.extend(loader.load())\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error loading document from {url}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2024-09-15T19:40:36+02:00', 'msip_label_1cf2ba15-c468-47c8-b178-cba8acf110ec_siteid': 'eb25818e-5bd5-49bf-99de-53e3e7b42630', 'msip_label_1cf2ba15-c468-47c8-b178-cba8acf110ec_method': 'Standard', 'msip_label_1cf2ba15-c468-47c8-b178-cba8acf110ec_enabled': 'True', 'author': 'Domingo Domènech Enric (ERNI)', 'moddate': '2024-09-15T19:40:36+02:00', 'source': 'docs/test_rag.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1'}, page_content='My favorite food is margarita pizza.  \\nThere are 47588 bottles in the tr uck.'),\n",
       " Document(metadata={'source': 'docs/test_rag.docx'}, page_content='My favorite food is margarita pizza.\\n\\nThere are 47588 bottles in the truck.\\n\\nToday is April 30, 2025.'),\n",
       " Document(metadata={'source': 'https://docs.streamlit.io/develop/quick-reference/release-notes', 'title': 'Release notes - Streamlit Docs', 'description': 'A changelog of highlights and fixes for each version of Streamlit.', 'language': 'No language found.'}, page_content=\"Release notes - Streamlit DocsDocumentationsearchSearchrocket_launchGet startedInstallationaddFundamentalsaddFirst stepsaddcodeDevelopConceptsaddAPI referenceaddTutorialsaddQuick referenceremoveCheat sheetRelease notesremove2025202420232022202120202019Pre-release featuresRoadmapopen_in_newweb_assetDeployConceptsaddStreamlit Community CloudaddSnowflakeOther platformsaddschoolKnowledge baseFAQInstalling dependenciesDeployment issuesHome/Develop/Quick reference/Release notesRelease notes\\nThis page lists highlights, bug fixes, and known issues for the latest release of Streamlit. If you're looking for information about nightly releases or experimental features, see Pre-release features.\\nUpgrade Streamlit\\nstarTipTo upgrade to the latest version of Streamlit, run:pip install --upgrade streamlit\\n\\nVersion 1.49.0 (latest)\\nRelease date: August 26, 2025\\nHighlights\\n\\n\\uf8ffüìÑ¬†Introducing st.pdf to beautifully render PDF documents in your app!\\n‚õèÔ∏è¬†Dataframes support cell selections!\\n‚ú®¬†You can add sparklines to st.metric!\\n‚úèÔ∏è¬†ListColumn is now editable!\\n\\uf8ffüìÇ¬†Users can upload a directory of files with st.file_uploader or st.chat_input.\\n\\nNotable Changes\\n\\n\\uf8ffüè∑Ô∏è¬†You can configure the labels of options in SelectboxColumn with a new format_func parameter (#12232, #6795).\\n\\uf8ffüçû¬†You can configure the duration of st.toast messages (#11872, #7047).\\n\\uf8ffüîë¬†st.form_submit_button has a key parameter (#12190, #12121).\\n\\uf8ffüåª¬†Markdown and heading dividers can be yellow (#12201).\\n\\uf8ffüí¨¬†st.dialog widths have a larger option (#12040, #8904).\\n\\uf8ffüíª¬†st.dataframe and st.data_editor have width and height to use with flex layouts (#11930).\\n\\uf8ffüñºÔ∏è¬†st.image, st.pyplot, and st.graphviz_chart have a width parameter to use them with flex layouts (#11952, #12212).\\n\\uf8ffüìà¬†Users can access the underlying data of a Vega chart through the toolbar. This includes all data passed to the chart, even if it's not displayed (#10311).\\n‚ò†Ô∏è¬†st.bokeh_chart is deprecated. Use the streamlit-bokeh custom component instead.\\n\\uf8ffüßπ¬†We removed deprecated commands and parameters: st.experimental_dialog, st.experimental_fragment, and caching's experimental_allow_widgets (#12167).\\n\\nOther Changes\\n\\n\\uf8ffüèÉ‚Äç‚ôÇÔ∏è¬†For better performance, st.slider will not rerun the app until the user releases the slider thumb (#11879, #4541).\\n\\uf8ffüíÖ¬†For improved custom theming, single mark charts use the first categorical chart color (#12162).\\n\\uf8ffüåê¬†For¬†st.logo, the¬†crossorigin¬†property can be configured by hosts (#12226).\\n\\uf8ffüé®¬†The colored decoration line at the top of Streamlit apps was removed (#12155).\\n\\uf8ffüëª¬†The copy-to-clipboard function of multiple elements gives a checkmark feedback to users when they copy something (#12141, #12172).\\n\\uf8ffü´•¬†Users can quickly hide or unhide all columns in a dataframe (#12164, #12082). Thanks, plumol!\\n‚ÑπÔ∏è Material icons were updated (#12264).\\n\\uf8ffüëΩ¬†Bug fix: CheckboxColumn uses the radii from the theming configuration options (#12263).\\n\\uf8ffü¶Ä¬†Bug fix: A column's menu is not accessible when the column is hidden (#12233, #12230). Thanks, plumol!\\n\\uf8ffü¶ã¬†Bug fix: Streamlit correctly caches Pydantic models (#12137, #10348).\\n\\uf8ffü¶é¬†Bug fix: st.plotly_chart correctly handles null selections (#12222, #12191).\\n\\uf8ffüêå¬†Bug fix: When using accept_new_options=True with st.selectbox, mobile users can access their keyboards (#12219, #12205).\\n\\uf8ffüï∏Ô∏è¬†Bug fix: Streamlit does not raise an error when the user's email is empty and server.showEmailPrompt is false (#12202, #12166). Thanks, wyattscarpenter!\\n\\uf8ffü¶ó¬†Bug fix: The drop area of st.file_uploader correctly truncates a long list of file types (#12192, #12189).\\n\\uf8ffü¶Ç¬†Bug fix: The corner radius of st.page_link matches the navigation widget instead of the border radius configured for buttons (#12181).\\n\\uf8ffü¶ü¬†Bug fix: Cached replay correctly handles element height and width for flex layouts (#12183).\\n\\uf8ffü¶†¬†Bug fix: When a client disconnects from a Streamlit server and the user dismisses the warning, the client will re-raise the warning while the app remains disconnected (#12178, #12113).\\n\\uf8ffü™∞¬†Bug fix: Identity provider logout was reverted to prevent redirect failures in st.logout() (#12179).\\n\\uf8ffü™≥¬†Bug fix: Currency symbols in column configuration are narrowly formatted (#11895).\\n\\uf8ffüï∑Ô∏è¬†Bug fix: Users can't remove files from st.file_uploader while the widget is disabled (#12180, #12146).\\n\\uf8ffüêû¬†Bug fix: pip install works correctly in Windows (#8952). Thanks, Dev-iL!\\n\\uf8ffüêù¬†Bug fix: The drop-down menu for st.time_input uses theme colors consistently with other elements (#12157).\\n\\uf8ffüêú¬†Bug fix: st.toast uses custom theme colors (#12160, #11951).\\n\\uf8ffü™≤¬†Bug fix: The width handling of custom components was updated to work with horizontal containers (#12148).\\n\\uf8ffüêõ¬†Bug fix: st.chat_input correctly resizes itself after the user submits a long message (#12132, #12079).\\n\\nOlder versions of Streamlit\\n\\n2025 release notes\\n2024 release notes\\n2023 release notes\\n2022 release notes\\n2021 release notes\\n2020 release notes\\n2019 release notes\\nPrevious: Cheat sheetNext: 2025forumStill have questions?Our forums are full of helpful information and Streamlit experts.HomeContact UsCommunity¬© 2025 Snowflake Inc.Cookie policyforum Ask AI\")]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split docs\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=5000,\n",
    "    chunk_overlap=1000,\n",
    ")\n",
    "\n",
    "document_chunks = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "OpenAIError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Tokenize and load the documents to the vector store\u001b[39;00m\n\u001b[1;32m      3\u001b[0m vector_db \u001b[38;5;241m=\u001b[39m Chroma\u001b[38;5;241m.\u001b[39mfrom_documents(\n\u001b[1;32m      4\u001b[0m     documents\u001b[38;5;241m=\u001b[39mdocument_chunks,\n\u001b[0;32m----> 5\u001b[0m     embedding\u001b[38;5;241m=\u001b[39m\u001b[43mOpenAIEmbeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m      6\u001b[0m )\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.12/envs/311/lib/python3.11/site-packages/langchain_openai/embeddings/base.py:338\u001b[0m, in \u001b[0;36mOpenAIEmbeddings.validate_environment\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    336\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhttp_client \u001b[38;5;241m=\u001b[39m httpx\u001b[38;5;241m.\u001b[39mClient(proxy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopenai_proxy)\n\u001b[1;32m    337\u001b[0m     sync_specific \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp_client\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhttp_client}\n\u001b[0;32m--> 338\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mclient_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msync_specific\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39membeddings  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39masync_client:\n\u001b[1;32m    340\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopenai_proxy \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhttp_async_client:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.12/envs/311/lib/python3.11/site-packages/openai/_client.py:105\u001b[0m, in \u001b[0;36mOpenAI.__init__\u001b[0;34m(self, api_key, organization, project, base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[1;32m    103\u001b[0m     api_key \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 105\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[1;32m    106\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    107\u001b[0m     )\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m api_key\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m organization \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mOpenAIError\u001b[0m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "source": [
    "# Tokenize and load the documents to the vector store\n",
    "\n",
    "vector_db = Chroma.from_documents(\n",
    "    documents=document_chunks,\n",
    "    embedding=OpenAIEmbeddings(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve\n",
    "\n",
    "def _get_context_retriever_chain(vector_db, llm):\n",
    "    retriever = vector_db.as_retriever()\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        (\"user\", \"{input}\"),\n",
    "        (\"user\", \"Given the above conversation, generate a search query to look up in order to get inforamtion relevant to the conversation, focusing on the most recent messages.\"),\n",
    "    ])\n",
    "    retriever_chain = create_history_aware_retriever(llm, retriever, prompt)\n",
    "\n",
    "    return retriever_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conversational_rag_chain(llm):\n",
    "    retriever_chain = _get_context_retriever_chain(vector_db, llm)\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\",\n",
    "        \"\"\"You are a helpful assistant. You will have to answer to user's queries.\n",
    "        You will have some context to help with your answers, but now always would be completely related or helpful.\n",
    "        You can also use your knowledge to assist answering the user's queries.\\n\n",
    "        {context}\"\"\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        (\"user\", \"{input}\"),\n",
    "    ])\n",
    "    stuff_documents_chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "    return create_retrieval_chain(retriever_chain, stuff_documents_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "OpenAIError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Augmented Generation\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m llm_stream_openai \u001b[38;5;241m=\u001b[39m \u001b[43mChatOpenAI\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-4o\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Here you could use \"o1-preview\" or \"o1-mini\" if you already have access to them\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstreaming\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m llm_stream_anthropic \u001b[38;5;241m=\u001b[39m ChatAnthropic(\n\u001b[1;32m     10\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclaude-3-5-sonnet-20240620\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     11\u001b[0m     temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m,\n\u001b[1;32m     12\u001b[0m     streaming\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     13\u001b[0m )\n\u001b[1;32m     15\u001b[0m llm_stream \u001b[38;5;241m=\u001b[39m llm_stream_openai  \u001b[38;5;66;03m# Select between OpenAI and Anthropic models for the response\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.12/envs/311/lib/python3.11/site-packages/langchain_core/load/serializable.py:130\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: D419\u001b[39;00m\n\u001b[0;32m--> 130\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.12/envs/311/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:516\u001b[0m, in \u001b[0;36mBaseChatOpenAI.validate_environment\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhttp_client \u001b[38;5;241m=\u001b[39m httpx\u001b[38;5;241m.\u001b[39mClient(proxy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopenai_proxy)\n\u001b[1;32m    515\u001b[0m     sync_specific \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp_client\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhttp_client}\n\u001b[0;32m--> 516\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_client \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mclient_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msync_specific\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    517\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\n\u001b[1;32m    518\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39masync_client:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.12/envs/311/lib/python3.11/site-packages/openai/_client.py:105\u001b[0m, in \u001b[0;36mOpenAI.__init__\u001b[0;34m(self, api_key, organization, project, base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[1;32m    103\u001b[0m     api_key \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 105\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[1;32m    106\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    107\u001b[0m     )\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m api_key\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m organization \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mOpenAIError\u001b[0m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "source": [
    "# Augmented Generation\n",
    "\n",
    "llm_stream_openai = ChatOpenAI(\n",
    "    model=\"gpt-4o\",  # Here you could use \"o1-preview\" or \"o1-mini\" if you already have access to them\n",
    "    temperature=0.3,\n",
    "    streaming=True,\n",
    ")\n",
    "\n",
    "llm_stream_anthropic = ChatAnthropic(\n",
    "    model=\"claude-3-5-sonnet-20240620\",\n",
    "    temperature=0.3,\n",
    "    streaming=True,\n",
    ")\n",
    "\n",
    "llm_stream = llm_stream_openai  # Select between OpenAI and Anthropic models for the response\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Hi\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Hi there! How can I assist you today?\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is the latest version of Streamlit?\"},\n",
    "]\n",
    "messages = [HumanMessage(content=m[\"content\"]) if m[\"role\"] == \"user\" else AIMessage(content=m[\"content\"]) for m in messages]\n",
    "\n",
    "conversation_rag_chain = get_conversational_rag_chain(llm_stream)\n",
    "response_message = \"*(RAG Response)*\\n\"\n",
    "for chunk in conversation_rag_chain.pick(\"answer\").stream({\"messages\": messages[:-1], \"input\": messages[-1].content}):\n",
    "    response_message += chunk\n",
    "    print(chunk, end=\"\", flush=True)\n",
    "\n",
    "messages.append({\"role\": \"assistant\", \"content\": response_message})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_dotenv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mload_dotenv\u001b[49m()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_dotenv' is not defined"
     ]
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1oUiDhM7pfr7W5ssz6XadegvJQv6XS0TrAR0Ts7Az8vQvwPsFd2mJQQJ99BDACYeBjFXJ3w3AAABACOGYfUz'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getenv(\"AZ_OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! Microsoft Azure is a cloud computing platform and service offered by Microsoft. It provides a wide range of cloud services, including computing power, storage, networking, databases, artificial intelligence, machine learning, and more. Azure enables businesses and developers to build, deploy, and manage applications and services through Microsoft-managed data centers located around the globe.\n",
      "\n",
      "Here are some key aspects of Azure:\n",
      "\n",
      "### 1. **Cloud Service Models**\n",
      "Azure supports various cloud service models to meet diverse needs:\n",
      "   - **Infrastructure as a Service (IaaS):** Provides virtualized computing resources like virtual machines (VMs), storage, and networking.\n",
      "   - **Platform as a Service (PaaS):** Offers tools and frameworks for developers to build, test, and deploy applications without worrying about underlying infrastructure.\n",
      "   - **Software as a Service (SaaS):** Hosts applications that users can access over the internet, such as Office 365.\n",
      "\n",
      "### 2. **Key Features**\n",
      "   - **Scalability:** Azure allows businesses to scale resources up or down based on demand.\n",
      "   - **Global Reach:** Azure operates in multiple regions worldwide, ensuring high availability and low latency.\n",
      "   - **Hybrid Cloud:** Azure integrates seamlessly with on-premises environments, enabling hybrid cloud solutions.\n",
      "   - **Security:** Azure provides robust security features, including encryption, compliance certifications, and advanced threat detection.\n",
      "\n",
      "### 3. **Popular Services**\n",
      "Azure offers hundreds of services across different categories. Some of the most popular ones include:\n",
      "   - **Azure Virtual Machines:** Run Windows or Linux VMs in the cloud.\n",
      "   - **Azure App Service:** Build and host web apps, mobile apps, and APIs.\n",
      "   - **Azure Blob Storage:** Store unstructured data like images, videos, and backups.\n",
      "   - **Azure SQL Database:** Fully managed relational database service.\n",
      "   - **Azure Kubernetes Service (AKS):** Deploy and manage containerized applications using Kubernetes.\n",
      "   - **Azure AI and Machine Learning:** Build intelligent applications using tools like Azure Cognitive Services and Azure Machine Learning.\n",
      "   - **Azure DevOps:** Tools for CI/CD pipelines, project management, and collaboration.\n",
      "\n",
      "### 4. **Pricing**\n",
      "Azure uses a pay-as-you-go pricing model, meaning customers only pay for the resources they use. It also offers free tiers for many services, allowing users to experiment and learn without incurring costs.\n",
      "\n",
      "### 5. **Integration with Microsoft Ecosystem**\n",
      "Azure integrates seamlessly with other Microsoft products, such as Windows Server, Active Directory, and Office 365. This makes it a preferred choice for organizations already using Microsoft technologies.\n",
      "\n",
      "### 6. **Use Cases**\n",
      "Azure is used across industries for various purposes:\n",
      "   - Hosting websites and applications.\n",
      "   - Data analytics and business intelligence.\n",
      "   - IoT (Internet of Things) solutions.\n",
      "   - Disaster recovery and backup.\n",
      "   - AI-powered applications and chatbots.\n",
      "\n",
      "### 7. **Competitors**\n",
      "Azure competes with other major cloud providers like Amazon Web Services (AWS), Google Cloud Platform (GCP), and IBM Cloud. Each platform has its strengths, but Azure is known for its enterprise-friendly features and strong hybrid cloud capabilities.\n",
      "\n",
      "### 8. **Certifications**\n",
      "Microsoft offers Azure certifications for individuals looking to build expertise in cloud computing. Popular certifications include:\n",
      "   - Microsoft Certified: Azure Fundamentals (for beginners).\n",
      "   - Microsoft Certified: Azure Administrator Associate.\n",
      "   - Microsoft Certified: Azure Solutions Architect Expert.\n",
      "\n",
      "Azure continues to evolve, introducing new services and features to meet the growing demands of businesses and developers worldwide. Whether you're a small startup or a large enterprise, Azure provides the tools and flexibility to innovate and succeed in the cloud."
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm_stream = AzureChatOpenAI(\n",
    "    azure_endpoint=os.getenv(\"AZ_OPENAI_ENDPOINT\"),\n",
    "    openai_api_version=\"2024-12-01-preview\",\n",
    "    model_name=\"gpt-4o\",\n",
    "    openai_api_key=os.getenv(\"AZ_OPENAI_API_KEY\"),\n",
    "    openai_api_type=\"azure\",\n",
    "    temperature=0.3,\n",
    "    streaming=True,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "prompt = \"Tell me something about Azure\"\n",
    "\n",
    "for chunk in llm_stream.stream(prompt):\n",
    "    print(chunk.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
