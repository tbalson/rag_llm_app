{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import dotenv\n",
    "from pathlib import Path\n",
    "\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from langchain_community.document_loaders.text import TextLoader\n",
    "from langchain_community.document_loaders import (\n",
    "    WebBaseLoader, \n",
    "    PyPDFLoader, \n",
    "    Docx2txtLoader,\n",
    ")\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.chains import create_history_aware_retriever, create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_doc_to_db():\n",
    "    # Use loader according to doc type\n",
    "    if \"rag_docs\" in st.session_state and st.session_state.rag_docs:\n",
    "        docs = [] \n",
    "        for doc_file in st.session_state.rag_docs:\n",
    "            if doc_file.name not in st.session_state.rag_sources:\n",
    "                if len(st.session_state.rag_sources) < DB_DOCS_LIMIT:\n",
    "                    os.makedirs(\"source_files\", exist_ok=True)\n",
    "                    file_path = f\"./source_files/{doc_file.name}\"\n",
    "                    with open(file_path, \"wb\") as file:\n",
    "                        file.write(doc_file.read())\n",
    "\n",
    "                    try:\n",
    "                        if doc_file.type == \"application/pdf\":\n",
    "                            loader = PyPDFLoader(file_path)\n",
    "                        elif doc_file.name.endswith(\".docx\"):\n",
    "                            loader = Docx2txtLoader(file_path)\n",
    "                        elif doc_file.type in [\"text/plain\", \"text/markdown\"]:\n",
    "                            loader = TextLoader(file_path)\n",
    "                        #elif doc_file.name.endswith(\".xlsx\"):\n",
    "                            #loader = UnstructuredExcelLoader(file_path, mode='elements')\n",
    "                        elif doc_file.name.endswith(\".xlsx\"):\n",
    "                            loader = AzureAIDocumentIntelligenceLoader(\n",
    "                                 api_endpoint=os.getenv(\"AZ_OPENAI_ENDPOINT\"),\n",
    "                                 api_key=os.getenv(\"AZ_OPENAI_API_KEY\"),\n",
    "                                 file_path=file_path,\n",
    "                                 api_model=\"prebuilt-layout\"\n",
    "                            )\n",
    "                        elif doc_file.name.endswith(\".py\"):\n",
    "                            loader = PythonLoader(file_path)\n",
    "                        elif doc_file.name.endswith(\".csv\"):\n",
    "                            loader = CSVLoader(file_path)\n",
    "                        else:\n",
    "                            st.warning(f\"Document type {doc_file.type} not supported.\")\n",
    "                            continue\n",
    "# Lets use a smarter lib https://python.langchain.com/v0.2/docs/integrations/document_loaders/microsoft_excel/ TBB 4/30/25\n",
    "                        docs.extend(loader.load())\n",
    "                        st.session_state.rag_sources.append(doc_file.name)\n",
    "\n",
    "                    except Exception as e:\n",
    "                        st.toast(f\"Error loading document {doc_file.name}: {e}\", icon=\"⚠️\")\n",
    "                        print(f\"Error loading document {doc_file.name}: {e}\")\n",
    "                    \n",
    "                    finally:\n",
    "                        os.remove(file_path)\n",
    "\n",
    "                else:\n",
    "                    st.error(F\"Maximum number of documents reached ({DB_DOCS_LIMIT}).\")\n",
    "\n",
    "        if docs:\n",
    "            _split_and_load_docs(docs)\n",
    "            st.toast(f\"Document *{str([doc_file.name for doc_file in st.session_state.rag_docs])[1:-1]}* loaded successfully.\", icon=\"✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load docs\n",
    "\n",
    "doc_paths = [\n",
    "    \"docs/test_rag.pdf\",\n",
    "    \"docs/test_rag.docx\",\n",
    "]\n",
    "\n",
    "docs = [] \n",
    "for doc_file in doc_paths:\n",
    "    file_path = Path(doc_file)\n",
    "\n",
    "    try:\n",
    "        if doc_file.endswith(\".pdf\"):\n",
    "            loader = PyPDFLoader(file_path)\n",
    "        elif doc_file.endswith(\".docx\"):\n",
    "            loader = Docx2txtLoader(file_path)\n",
    "        elif doc_file.endswith(\".txt\") or doc_file.name.endswith(\".md\"):\n",
    "            loader = TextLoader(file_path)\n",
    "        elif doc_file.name.endswith(\".xlsx\"):\n",
    "            loader = AzureAIDocumentIntelligenceLoader(\n",
    "                api_endpoint=os.getenv(\"AZ_OPENAI_ENDPOINT\"),\n",
    "                api_key=os.getenv(\"AZ_OPENAI_API_KEY\"),\n",
    "                file_path=file_path,\n",
    "                api_model=\"prebuilt-layout\"\n",
    "                            )  \n",
    "        else:\n",
    "            print(f\"Document type {doc_file.type} not supported.\")\n",
    "            continue\n",
    "\n",
    "        docs.extend(loader.load())\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading document {doc_file.name}: {e}\")\n",
    "\n",
    "\n",
    "# Load URLs\n",
    "\n",
    "url = \"https://docs.streamlit.io/develop/quick-reference/release-notes\"\n",
    "try:\n",
    "    loader = WebBaseLoader(url)\n",
    "    docs.extend(loader.load())\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error loading document from {url}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2024-09-15T19:40:36+02:00', 'msip_label_1cf2ba15-c468-47c8-b178-cba8acf110ec_siteid': 'eb25818e-5bd5-49bf-99de-53e3e7b42630', 'msip_label_1cf2ba15-c468-47c8-b178-cba8acf110ec_method': 'Standard', 'msip_label_1cf2ba15-c468-47c8-b178-cba8acf110ec_enabled': 'True', 'author': 'Domingo Domènech Enric (ERNI)', 'moddate': '2024-09-15T19:40:36+02:00', 'source': 'docs/test_rag.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1'}, page_content='My favorite food is margarita pizza.  \\nThere are 47588 bottles in the tr uck.'),\n",
       " Document(metadata={'source': 'docs/test_rag.docx'}, page_content='My favorite food is margarita pizza.\\n\\nThere are 47588 bottles in the truck.\\n\\nToday is April 30, 2025.'),\n",
       " Document(metadata={'source': 'https://docs.streamlit.io/develop/quick-reference/release-notes', 'title': 'Release notes - Streamlit Docs', 'description': 'A changelog of highlights and fixes for each version of Streamlit.', 'language': 'No language found.'}, page_content=\"Release notes - Streamlit DocsDocumentationsearchSearchrocket_launchGet startedInstallationaddFundamentalsaddFirst stepsaddcodeDevelopConceptsaddAPI referenceaddTutorialsaddQuick referenceremoveCheat sheetRelease notesremove2025202420232022202120202019Pre-release featuresRoadmapopen_in_newweb_assetDeployConceptsaddStreamlit Community CloudaddSnowflakeOther platformsaddschoolKnowledge baseFAQInstalling dependenciesDeployment issuesHome/Develop/Quick reference/Release notesRelease notes\\nThis page lists highlights, bug fixes, and known issues for the latest release of Streamlit. If you're looking for information about nightly releases or experimental features, see Pre-release features.\\nUpgrade Streamlit\\nstarTipTo upgrade to the latest version of Streamlit, run:pip install --upgrade streamlit\\n\\nVersion 1.45.0 (latest)\\nRelease date: April 29, 2025\\nHighlights\\n\\nAnnouncing the general availability of st.user, a dict-like object to access information about the current user.\\n\\nNotable Changes\\n\\nst.multiselect and st.selectbox have a new parameter to let users add new options.\\nst.context has new attributes: url, ip_address, and is_embedded.\\nText alerts and exceptions have a new width parameter (#11142).\\nYou can set the tab index for st.components.v1.html and st.components.v1.iframe (#11065, #7969).\\nWhen you pass a CSS file's path to st.html, Streamlit will automatically insert <style> tags and avoid creating extra space in the app (#10979, #9388, #10027).\\nYou can add an icon to the left of the value in st.text_input and st.number_input.\\n\\nOther Changes\\n\\nPer the scheduled deprecation, st.experimental_audio_input has been removed. Use st.audio_input instead.\\nVarious elements received styling tweaks for consistency and compatibility with advanced theming (#10916, #10930, #10915, #10944, #10990, #11033, #11034).\\nThe element toolbar sizing and spacing was adjusted for improved UX (#11135, #11155).\\nBug fix: Streamlit does not display a frontend error when displaying an empty dataframe (#11100, #11064).\\nBug fix: st.context retains its information when calling st.rerun (#11113, #11111).\\nBug fix: st.camera_input has the correct color and hover effect when disabled (#11116).\\nBug fix: st.audio_input has consistent color and hover effects with other widgets (#11118).\\nBug fix: st.logo displays correctly when the sidebar is resized (#11063, #11062).\\nBug fix: st.file_uploader can handle multi-part file extensions in its type parameter (#11043, #11041). Thanks, moutayam!\\nBug fix: theme.fontFaces correctly supports font style (#11098, #11097).\\nBug fix: streamlit init specifies file encoding to avoid errors in systems where UTF-8 is not the default (#11090, #11086). Thanks, ashm-dev!\\nBug fix: In the sidebar, space is reserved for the scrollbar to prevent flickering from resizing (#10733, #10310).\\nBug fix: st.logo supports SVGs defined with a viewBox (#11038, #10904).\\nBug fix: st.date_input raises an error in the UI if a user enters a date outside of the specified allowed range (#10764, #8475).\\nBug fix: st.snow and st.balloons don't incorrectly rerun during a fragment rerun (#11015, #10961).\\nBug fix: When updating config.tomlduring development, Streamlit will elegantly handle invalid TOML formatting and reload the configuration file on the next save (#10857, #1256, #8320).\\nBug fix: Streamlit applies the correct hover effect when colored text is used in button labels (#10996, #8767).\\nBug fix: Streamlit ignores __init__.py and dotfiles in the /pages directory when automatically declaring pages in a multipage app (#11009, #11006).\\nst.write received an optimization tweak for rendering strings (#10985).\\nBug fix: st.html renders at 100% width for correct sizing (#10976, #10964).\\nBug fix: Page links become disabled if a client disconnects from the Streamlit server (#10946, #9198).\\nBug fix: Streamlit supports newer emojis in page icons (#10912, #11154).\\nBug fix: st.exception only shows links to Google and ChatGPT when the app is being accessed through localhost (#10971, #10924).\\nBug fix: st.chat_input will expand to show multi-line placeholder text in most browsers. Firefox does not support this fix (#10931, #10611).\\nBug fix: Streamlit elegantly catches a TypeError when concurrent changes to rows and columns cause a failure in serialization (#10954, #10937).\\nBug fix: Streamlit cleanly handles non-ASCII characters in anchor links, which may change some anchors in existing apps (#10929, #8114).\\nBug fix: To prevent a race condition, session information is not immediately cleared unless a new session message is received (#9886, #9767).\\nBug fix: streamlit config show correctly displays client.showErrorDetails as a string instead of a list (#10921, #10913).\\nBug fix: st.selectbox does not lose its value if a partial edit is abandoned (#10891).\\nBug fix: st.badge doesn't falsely show rainbow as a color option (#10896).\\nBug fix: To avoid a file lock conflict the occurs with some IDEs, Streamlit's file watcher utilities retries reading files when blocked (#10868, #4486). Thanks, Morridin!\\nBug fix: st.selectbox and st.multiselect have consistent color and spacing for placeholder text (#10865).\\nBug fix: Context managers correctly handle form elements (#10752, #8761). Thanks, SrGesus!\\nBug fix: st.link_button and st.tabs remain active when a client disconnects from a Streamlit server (#10861).\\n\\nOlder versions of Streamlit\\n\\n2025 release notes\\n2024 release notes\\n2023 release notes\\n2022 release notes\\n2021 release notes\\n2020 release notes\\n2019 release notes\\nPrevious: Cheat sheetNext: 2025forumStill have questions?Our forums are full of helpful information and Streamlit experts.HomeContact UsCommunity© 2025 Snowflake Inc.Cookie policyforum Ask AI\")]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split docs\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=5000,\n",
    "    chunk_overlap=1000,\n",
    ")\n",
    "\n",
    "document_chunks = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "OpenAIError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Tokenize and load the documents to the vector store\u001b[39;00m\n\u001b[1;32m      3\u001b[0m vector_db \u001b[38;5;241m=\u001b[39m Chroma\u001b[38;5;241m.\u001b[39mfrom_documents(\n\u001b[1;32m      4\u001b[0m     documents\u001b[38;5;241m=\u001b[39mdocument_chunks,\n\u001b[0;32m----> 5\u001b[0m     embedding\u001b[38;5;241m=\u001b[39m\u001b[43mOpenAIEmbeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m      6\u001b[0m )\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.12/envs/311/lib/python3.11/site-packages/langchain_openai/embeddings/base.py:338\u001b[0m, in \u001b[0;36mOpenAIEmbeddings.validate_environment\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    336\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhttp_client \u001b[38;5;241m=\u001b[39m httpx\u001b[38;5;241m.\u001b[39mClient(proxy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopenai_proxy)\n\u001b[1;32m    337\u001b[0m     sync_specific \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp_client\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhttp_client}\n\u001b[0;32m--> 338\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mclient_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msync_specific\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39membeddings  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39masync_client:\n\u001b[1;32m    340\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopenai_proxy \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhttp_async_client:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.12/envs/311/lib/python3.11/site-packages/openai/_client.py:105\u001b[0m, in \u001b[0;36mOpenAI.__init__\u001b[0;34m(self, api_key, organization, project, base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[1;32m    103\u001b[0m     api_key \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 105\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[1;32m    106\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    107\u001b[0m     )\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m api_key\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m organization \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mOpenAIError\u001b[0m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "source": [
    "# Tokenize and load the documents to the vector store\n",
    "\n",
    "vector_db = Chroma.from_documents(\n",
    "    documents=document_chunks,\n",
    "    embedding=OpenAIEmbeddings(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve\n",
    "\n",
    "def _get_context_retriever_chain(vector_db, llm):\n",
    "    retriever = vector_db.as_retriever()\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        (\"user\", \"{input}\"),\n",
    "        (\"user\", \"Given the above conversation, generate a search query to look up in order to get inforamtion relevant to the conversation, focusing on the most recent messages.\"),\n",
    "    ])\n",
    "    retriever_chain = create_history_aware_retriever(llm, retriever, prompt)\n",
    "\n",
    "    return retriever_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conversational_rag_chain(llm):\n",
    "    retriever_chain = _get_context_retriever_chain(vector_db, llm)\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\",\n",
    "        \"\"\"You are a helpful assistant. You will have to answer to user's queries.\n",
    "        You will have some context to help with your answers, but now always would be completely related or helpful.\n",
    "        You can also use your knowledge to assist answering the user's queries.\\n\n",
    "        {context}\"\"\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        (\"user\", \"{input}\"),\n",
    "    ])\n",
    "    stuff_documents_chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "    return create_retrieval_chain(retriever_chain, stuff_documents_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "OpenAIError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOpenAIError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Augmented Generation\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m llm_stream_openai = \u001b[43mChatOpenAI\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgpt-4o\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Here you could use \"o1-preview\" or \"o1-mini\" if you already have access to them\u001b[39;49;00m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstreaming\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m llm_stream_anthropic = ChatAnthropic(\n\u001b[32m     10\u001b[39m     model=\u001b[33m\"\u001b[39m\u001b[33mclaude-3-5-sonnet-20240620\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     11\u001b[39m     temperature=\u001b[32m0.3\u001b[39m,\n\u001b[32m     12\u001b[39m     streaming=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     13\u001b[39m )\n\u001b[32m     15\u001b[39m llm_stream = llm_stream_openai  \u001b[38;5;66;03m# Select between OpenAI and Anthropic models for the response\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.12/envs/311/lib/python3.11/site-packages/langchain_core/load/serializable.py:112\u001b[39m, in \u001b[36mSerializable.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    110\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Any, **kwargs: Any) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    111\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m112\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[31m[... skipping hidden 1 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.12/envs/311/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:516\u001b[39m, in \u001b[36mBaseChatOpenAI.validate_environment\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    514\u001b[39m         \u001b[38;5;28mself\u001b[39m.http_client = httpx.Client(proxy=\u001b[38;5;28mself\u001b[39m.openai_proxy)\n\u001b[32m    515\u001b[39m     sync_specific = {\u001b[33m\"\u001b[39m\u001b[33mhttp_client\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.http_client}\n\u001b[32m--> \u001b[39m\u001b[32m516\u001b[39m     \u001b[38;5;28mself\u001b[39m.root_client = \u001b[43mopenai\u001b[49m\u001b[43m.\u001b[49m\u001b[43mOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mclient_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msync_specific\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m    517\u001b[39m     \u001b[38;5;28mself\u001b[39m.client = \u001b[38;5;28mself\u001b[39m.root_client.chat.completions\n\u001b[32m    518\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.async_client:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.12/envs/311/lib/python3.11/site-packages/openai/_client.py:105\u001b[39m, in \u001b[36mOpenAI.__init__\u001b[39m\u001b[34m(self, api_key, organization, project, base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[39m\n\u001b[32m    103\u001b[39m     api_key = os.environ.get(\u001b[33m\"\u001b[39m\u001b[33mOPENAI_API_KEY\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    104\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[32m    106\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    107\u001b[39m     )\n\u001b[32m    108\u001b[39m \u001b[38;5;28mself\u001b[39m.api_key = api_key\n\u001b[32m    110\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m organization \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mOpenAIError\u001b[39m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "source": [
    "# Augmented Generation\n",
    "\n",
    "llm_stream_openai = ChatOpenAI(\n",
    "    model=\"gpt-4o\",  # Here you could use \"o1-preview\" or \"o1-mini\" if you already have access to them\n",
    "    temperature=0.3,\n",
    "    streaming=True,\n",
    ")\n",
    "\n",
    "llm_stream_anthropic = ChatAnthropic(\n",
    "    model=\"claude-3-5-sonnet-20240620\",\n",
    "    temperature=0.3,\n",
    "    streaming=True,\n",
    ")\n",
    "\n",
    "llm_stream = llm_stream_openai  # Select between OpenAI and Anthropic models for the response\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Hi\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Hi there! How can I assist you today?\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is the latest version of Streamlit?\"},\n",
    "]\n",
    "messages = [HumanMessage(content=m[\"content\"]) if m[\"role\"] == \"user\" else AIMessage(content=m[\"content\"]) for m in messages]\n",
    "\n",
    "conversation_rag_chain = get_conversational_rag_chain(llm_stream)\n",
    "response_message = \"*(RAG Response)*\\n\"\n",
    "for chunk in conversation_rag_chain.pick(\"answer\").stream({\"messages\": messages[:-1], \"input\": messages[-1].content}):\n",
    "    response_message += chunk\n",
    "    print(chunk, end=\"\", flush=True)\n",
    "\n",
    "messages.append({\"role\": \"assistant\", \"content\": response_message})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1oUiDhM7pfr7W5ssz6XadegvJQv6XS0TrAR0Ts7Az8vQvwPsFd2mJQQJ99BDACYeBjFXJ3w3AAABACOGYfUz'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getenv(\"AZ_OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Microsoft Azure, commonly referred to as **Azure**, is a comprehensive cloud computing platform and service offered by Microsoft. It provides a wide range of cloud services, including computing, analytics, storage, networking, and more, enabling businesses and developers to build, deploy, and manage applications and services through Microsoft-managed data centers worldwide.\n",
      "\n",
      "Here are some key aspects of Azure:\n",
      "\n",
      "---\n",
      "\n",
      "### **1. Core Services**\n",
      "Azure offers a broad spectrum of services, categorized into several domains:\n",
      "\n",
      "- **Compute**: Virtual machines (VMs), containers, serverless computing (Azure Functions), and Kubernetes (AKS).\n",
      "- **Storage**: Scalable cloud storage solutions, including Blob Storage, Disk Storage, and File Storage.\n",
      "- **Networking**: Virtual networks, load balancers, VPN gateways, and content delivery networks (CDNs).\n",
      "- **Databases**: Managed database services, including Azure SQL Database, Cosmos DB, and PostgreSQL.\n",
      "- **AI and Machine Learning**: Tools like Azure Machine Learning, Cognitive Services, and Bot Services for building intelligent applications.\n",
      "- **Analytics**: Data processing and analytics services like Azure Synapse Analytics, Data Lake, and Stream Analytics.\n",
      "- **DevOps**: Azure DevOps for CI/CD pipelines, Git repositories, and project management.\n",
      "- **Security**: Identity and access management (Azure Active Directory), threat protection, and compliance tools.\n",
      "\n",
      "---\n",
      "\n",
      "### **2. Deployment Models**\n",
      "Azure supports multiple deployment models to suit different business needs:\n",
      "- **Public Cloud**: Fully hosted on Azure's infrastructure.\n",
      "- **Hybrid Cloud**: Combines on-premises infrastructure with Azure services using tools like Azure Arc.\n",
      "- **Multi-Cloud**: Integrates Azure with other cloud providers like AWS or Google Cloud.\n",
      "- **Edge Computing**: Azure Stack allows running Azure services on-premises or at the edge.\n",
      "\n",
      "---\n",
      "\n",
      "### **3. Global Reach**\n",
      "Azure operates in **60+ regions** across the globe, making it one of the largest cloud platforms in terms of geographic reach. This allows businesses to deploy applications closer to their users, ensuring low latency and compliance with local regulations.\n",
      "\n",
      "---\n",
      "\n",
      "### **4. Pay-As-You-Go Pricing**\n",
      "Azure follows a **pay-as-you-go** pricing model, meaning businesses only pay for the resources they use. This makes it cost-effective and scalable, especially for startups and enterprises looking to optimize their IT budgets.\n",
      "\n",
      "---\n",
      "\n",
      "### **5. Integration with Microsoft Ecosystem**\n",
      "Azure integrates seamlessly with Microsoft's ecosystem, including tools like:\n",
      "- **Windows Server**\n",
      "- **Microsoft 365**\n",
      "- **Power Platform**\n",
      "- **Visual Studio**\n",
      "This makes it a natural choice for organizations already using Microsoft products.\n",
      "\n",
      "---\n",
      "\n",
      "### **6. Popular Use Cases**\n",
      "Azure is used for a wide range of applications, such as:\n",
      "- Hosting websites and web applications.\n",
      "- Running virtual machines and containers.\n",
      "- Big data analytics and real-time data processing.\n",
      "- Building AI-powered applications.\n",
      "- Disaster recovery and backup solutions.\n",
      "- Internet of Things (IoT) applications.\n",
      "\n",
      "---\n",
      "\n",
      "### **7. Security and Compliance**\n",
      "Azure is designed with a strong focus on **security** and **compliance**:\n",
      "- It offers built-in tools to protect data, applications, and infrastructure.\n",
      "- It complies with global standards like GDPR, HIPAA, ISO 27001, and more.\n",
      "- Azure Sentinel provides advanced threat detection and response capabilities.\n",
      "\n",
      "---\n",
      "\n",
      "### **8. Azure Marketplace**\n",
      "Azure Marketplace is an online store where developers and businesses can find, try, and deploy software solutions, including pre-configured applications, virtual machine images, and services from third-party vendors.\n",
      "\n",
      "---\n",
      "\n",
      "### **9. Competitors**\n",
      "Azure is one of the leading cloud platforms, competing with other major providers like:\n",
      "- **Amazon Web Services (AWS)**\n",
      "- **Google Cloud Platform (GCP)**\n",
      "- **IBM Cloud**\n",
      "- **Oracle Cloud**\n",
      "\n",
      "---\n",
      "\n",
      "### **10. Learning and Certification**\n",
      "Microsoft offers a variety of certifications to help individuals and teams build expertise in Azure, such as:\n",
      "- **Azure Fundamentals (AZ-900)**\n",
      "- **Azure Administrator (AZ-104)**\n",
      "- **Azure Solutions Architect (AZ-305)**\n",
      "- **Azure DevOps Engineer (AZ-400)**\n",
      "\n",
      "These certifications are highly valued in the IT industry.\n",
      "\n",
      "---\n",
      "\n",
      "In summary, Azure is a versatile and powerful cloud platform that caters to businesses of all sizes, offering tools and services to innovate, scale, and transform their operations in the digital age."
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm_stream = AzureChatOpenAI(\n",
    "    azure_endpoint=os.getenv(\"AZ_OPENAI_ENDPOINT\"),\n",
    "    openai_api_version=\"2024-12-01-preview\",\n",
    "    model_name=\"gpt-4o\",\n",
    "    openai_api_key=os.getenv(\"AZ_OPENAI_API_KEY\"),\n",
    "    openai_api_type=\"azure\",\n",
    "    temperature=0.3,\n",
    "    streaming=True,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "prompt = \"Tell me something about Azure\"\n",
    "\n",
    "for chunk in llm_stream.stream(prompt):\n",
    "    print(chunk.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
